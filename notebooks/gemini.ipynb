{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f5e9b472",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/arthur/miniconda3/envs/flwr/lib/python3.12/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "2025-06-11 18:14:22,578\tINFO util.py:154 -- Missing packages: ['ipywidgets']. Run `pip install -U ipywidgets`, then restart the notebook server for rich notebook output.\n"
     ]
    }
   ],
   "source": [
    "from collections import OrderedDict\n",
    "import warnings\n",
    "\n",
    "import flwr as fl\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import DataLoader, random_split\n",
    "from torchvision.transforms import transforms\n",
    "\n",
    "# Importar o MedMNIST\n",
    "from medmnist import OrganMNIST3D"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8448f614",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ToTensor:\n",
    "    def __call__(self, x):\n",
    "        return torch.from_numpy(x).float()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "eb8b33fc",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[93mWARNING \u001b[0m:   DEPRECATED FEATURE: flwr.simulation.start_simulation() is deprecated.\n",
      "\tInstead, use the `flwr run` CLI command to start a local simulation in your Flower app, as shown for example below:\n",
      "\n",
      "\t\t$ flwr new  # Create a new Flower app from a template\n",
      "\n",
      "\t\t$ flwr run  # Run the Flower app in Simulation Mode\n",
      "\n",
      "\tUsing `start_simulation()` is deprecated.\n",
      "\n",
      "            This is a deprecated feature. It will be removed\n",
      "            entirely in future versions of Flower.\n",
      "        \n",
      "\u001b[92mINFO \u001b[0m:      Starting Flower simulation, config: num_rounds=3, no round_timeout\n",
      "2025-06-11 18:31:10,205\tINFO worker.py:1771 -- Started a local Ray instance.\n",
      "\u001b[92mINFO \u001b[0m:      Flower VCE: Ray initialized with resources: {'accelerator_type:G': 1.0, 'node:__internal_head__': 1.0, 'node:143.106.45.41': 1.0, 'CPU': 12.0, 'object_store_memory': 15811032268.0, 'memory': 31622064539.0, 'GPU': 1.0}\n",
      "\u001b[92mINFO \u001b[0m:      Optimize your simulation with Flower VCE: https://flower.ai/docs/framework/how-to-run-simulations.html\n",
      "\u001b[92mINFO \u001b[0m:      No `client_resources` specified. Using minimal resources for clients.\n",
      "\u001b[92mINFO \u001b[0m:      Flower VCE: Resources for each Virtual Client: {'num_cpus': 1, 'num_gpus': 0.0}\n",
      "\u001b[92mINFO \u001b[0m:      Flower VCE: Creating VirtualClientEngineActorPool with 12 actors\n",
      "\u001b[92mINFO \u001b[0m:      [INIT]\n",
      "\u001b[92mINFO \u001b[0m:      Requesting initial parameters from one random client\n",
      "\u001b[91mERROR \u001b[0m:     Traceback (most recent call last):\n",
      "  File \"/home/arthur/miniconda3/envs/flwr/lib/python3.12/site-packages/flwr/simulation/ray_transport/ray_client_proxy.py\", line 95, in _submit_job\n",
      "    out_mssg, updated_context = self.actor_pool.get_client_result(\n",
      "                                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/arthur/miniconda3/envs/flwr/lib/python3.12/site-packages/flwr/simulation/ray_transport/ray_actor.py\", line 401, in get_client_result\n",
      "    return self._fetch_future_result(cid)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/arthur/miniconda3/envs/flwr/lib/python3.12/site-packages/flwr/simulation/ray_transport/ray_actor.py\", line 282, in _fetch_future_result\n",
      "    res_cid, out_mssg, updated_context = ray.get(\n",
      "                                         ^^^^^^^^\n",
      "  File \"/home/arthur/miniconda3/envs/flwr/lib/python3.12/site-packages/ray/_private/auto_init_hook.py\", line 21, in auto_init_wrapper\n",
      "    return fn(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/arthur/miniconda3/envs/flwr/lib/python3.12/site-packages/ray/_private/client_mode_hook.py\", line 103, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/arthur/miniconda3/envs/flwr/lib/python3.12/site-packages/ray/_private/worker.py\", line 2639, in get\n",
      "    values, debugger_breakpoint = worker.get_objects(object_refs, timeout=timeout)\n",
      "                                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/arthur/miniconda3/envs/flwr/lib/python3.12/site-packages/ray/_private/worker.py\", line 864, in get_objects\n",
      "    raise value.as_instanceof_cause()\n",
      "ray.exceptions.RayTaskError(ClientAppException): \u001b[36mray::ClientAppActor.run()\u001b[39m (pid=1336571, ip=143.106.45.41, actor_id=447bc0f726f62603dbf37b8901000000, repr=<flwr.simulation.ray_transport.ray_actor.ClientAppActor object at 0x7eff661aa330>)\n",
      "                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/arthur/miniconda3/envs/flwr/lib/python3.12/site-packages/flwr/client/client_app.py\", line 144, in __call__\n",
      "    return self._call(message, context)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/arthur/miniconda3/envs/flwr/lib/python3.12/site-packages/flwr/client/client_app.py\", line 128, in ffn\n",
      "    out_message = handle_legacy_message_from_msgtype(\n",
      "                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/arthur/miniconda3/envs/flwr/lib/python3.12/site-packages/flwr/client/message_handler/message_handler.py\", line 96, in handle_legacy_message_from_msgtype\n",
      "    client = client_fn(context)\n",
      "             ^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/arthur/miniconda3/envs/flwr/lib/python3.12/site-packages/flwr/client/client_app.py\", line 72, in adaptor_fn\n",
      "    return client_fn(str(cid))  # type: ignore\n",
      "           ^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/tmp/ipykernel_1330781/2997288950.py\", line 126, in client_fn\n",
      "  File \"/home/arthur/miniconda3/envs/flwr/lib/python3.12/site-packages/torch/nn/modules/module.py\", line 1355, in to\n",
      "    return self._apply(convert)\n",
      "           ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/arthur/miniconda3/envs/flwr/lib/python3.12/site-packages/torch/nn/modules/module.py\", line 915, in _apply\n",
      "    module._apply(fn)\n",
      "  File \"/home/arthur/miniconda3/envs/flwr/lib/python3.12/site-packages/torch/nn/modules/module.py\", line 915, in _apply\n",
      "    module._apply(fn)\n",
      "  File \"/home/arthur/miniconda3/envs/flwr/lib/python3.12/site-packages/torch/nn/modules/module.py\", line 942, in _apply\n",
      "    param_applied = fn(param)\n",
      "                    ^^^^^^^^^\n",
      "  File \"/home/arthur/miniconda3/envs/flwr/lib/python3.12/site-packages/torch/nn/modules/module.py\", line 1341, in convert\n",
      "    return t.to(\n",
      "           ^^^^^\n",
      "  File \"/home/arthur/miniconda3/envs/flwr/lib/python3.12/site-packages/torch/cuda/__init__.py\", line 372, in _lazy_init\n",
      "    torch._C._cuda_init()\n",
      "RuntimeError: No CUDA GPUs are available\n",
      "\n",
      "The above exception was the direct cause of the following exception:\n",
      "\n",
      "\u001b[36mray::ClientAppActor.run()\u001b[39m (pid=1336571, ip=143.106.45.41, actor_id=447bc0f726f62603dbf37b8901000000, repr=<flwr.simulation.ray_transport.ray_actor.ClientAppActor object at 0x7eff661aa330>)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/arthur/miniconda3/envs/flwr/lib/python3.12/site-packages/flwr/simulation/ray_transport/ray_actor.py\", line 64, in run\n",
      "    raise ClientAppException(str(ex)) from ex\n",
      "flwr.client.client_app.ClientAppException: \n",
      "Exception ClientAppException occurred. Message: No CUDA GPUs are available\n",
      "\n",
      "\u001b[91mERROR \u001b[0m:     \u001b[36mray::ClientAppActor.run()\u001b[39m (pid=1336571, ip=143.106.45.41, actor_id=447bc0f726f62603dbf37b8901000000, repr=<flwr.simulation.ray_transport.ray_actor.ClientAppActor object at 0x7eff661aa330>)\n",
      "                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/arthur/miniconda3/envs/flwr/lib/python3.12/site-packages/flwr/client/client_app.py\", line 144, in __call__\n",
      "    return self._call(message, context)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/arthur/miniconda3/envs/flwr/lib/python3.12/site-packages/flwr/client/client_app.py\", line 128, in ffn\n",
      "    out_message = handle_legacy_message_from_msgtype(\n",
      "                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/arthur/miniconda3/envs/flwr/lib/python3.12/site-packages/flwr/client/message_handler/message_handler.py\", line 96, in handle_legacy_message_from_msgtype\n",
      "    client = client_fn(context)\n",
      "             ^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/arthur/miniconda3/envs/flwr/lib/python3.12/site-packages/flwr/client/client_app.py\", line 72, in adaptor_fn\n",
      "    return client_fn(str(cid))  # type: ignore\n",
      "           ^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/tmp/ipykernel_1330781/2997288950.py\", line 126, in client_fn\n",
      "  File \"/home/arthur/miniconda3/envs/flwr/lib/python3.12/site-packages/torch/nn/modules/module.py\", line 1355, in to\n",
      "    return self._apply(convert)\n",
      "           ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/arthur/miniconda3/envs/flwr/lib/python3.12/site-packages/torch/nn/modules/module.py\", line 915, in _apply\n",
      "    module._apply(fn)\n",
      "  File \"/home/arthur/miniconda3/envs/flwr/lib/python3.12/site-packages/torch/nn/modules/module.py\", line 915, in _apply\n",
      "    module._apply(fn)\n",
      "  File \"/home/arthur/miniconda3/envs/flwr/lib/python3.12/site-packages/torch/nn/modules/module.py\", line 942, in _apply\n",
      "    param_applied = fn(param)\n",
      "                    ^^^^^^^^^\n",
      "  File \"/home/arthur/miniconda3/envs/flwr/lib/python3.12/site-packages/torch/nn/modules/module.py\", line 1341, in convert\n",
      "    return t.to(\n",
      "           ^^^^^\n",
      "  File \"/home/arthur/miniconda3/envs/flwr/lib/python3.12/site-packages/torch/cuda/__init__.py\", line 372, in _lazy_init\n",
      "    torch._C._cuda_init()\n",
      "RuntimeError: No CUDA GPUs are available\n",
      "\n",
      "The above exception was the direct cause of the following exception:\n",
      "\n",
      "\u001b[36mray::ClientAppActor.run()\u001b[39m (pid=1336571, ip=143.106.45.41, actor_id=447bc0f726f62603dbf37b8901000000, repr=<flwr.simulation.ray_transport.ray_actor.ClientAppActor object at 0x7eff661aa330>)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/arthur/miniconda3/envs/flwr/lib/python3.12/site-packages/flwr/simulation/ray_transport/ray_actor.py\", line 64, in run\n",
      "    raise ClientAppException(str(ex)) from ex\n",
      "flwr.client.client_app.ClientAppException: \n",
      "Exception ClientAppException occurred. Message: No CUDA GPUs are available\n",
      "\u001b[91mERROR \u001b[0m:     \u001b[36mray::ClientAppActor.run()\u001b[39m (pid=1336571, ip=143.106.45.41, actor_id=447bc0f726f62603dbf37b8901000000, repr=<flwr.simulation.ray_transport.ray_actor.ClientAppActor object at 0x7eff661aa330>)\n",
      "                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/arthur/miniconda3/envs/flwr/lib/python3.12/site-packages/flwr/client/client_app.py\", line 144, in __call__\n",
      "    return self._call(message, context)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/arthur/miniconda3/envs/flwr/lib/python3.12/site-packages/flwr/client/client_app.py\", line 128, in ffn\n",
      "    out_message = handle_legacy_message_from_msgtype(\n",
      "                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/arthur/miniconda3/envs/flwr/lib/python3.12/site-packages/flwr/client/message_handler/message_handler.py\", line 96, in handle_legacy_message_from_msgtype\n",
      "    client = client_fn(context)\n",
      "             ^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/arthur/miniconda3/envs/flwr/lib/python3.12/site-packages/flwr/client/client_app.py\", line 72, in adaptor_fn\n",
      "    return client_fn(str(cid))  # type: ignore\n",
      "           ^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/tmp/ipykernel_1330781/2997288950.py\", line 126, in client_fn\n",
      "  File \"/home/arthur/miniconda3/envs/flwr/lib/python3.12/site-packages/torch/nn/modules/module.py\", line 1355, in to\n",
      "    return self._apply(convert)\n",
      "           ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/arthur/miniconda3/envs/flwr/lib/python3.12/site-packages/torch/nn/modules/module.py\", line 915, in _apply\n",
      "    module._apply(fn)\n",
      "  File \"/home/arthur/miniconda3/envs/flwr/lib/python3.12/site-packages/torch/nn/modules/module.py\", line 915, in _apply\n",
      "    module._apply(fn)\n",
      "  File \"/home/arthur/miniconda3/envs/flwr/lib/python3.12/site-packages/torch/nn/modules/module.py\", line 942, in _apply\n",
      "    param_applied = fn(param)\n",
      "                    ^^^^^^^^^\n",
      "  File \"/home/arthur/miniconda3/envs/flwr/lib/python3.12/site-packages/torch/nn/modules/module.py\", line 1341, in convert\n",
      "    return t.to(\n",
      "           ^^^^^\n",
      "  File \"/home/arthur/miniconda3/envs/flwr/lib/python3.12/site-packages/torch/cuda/__init__.py\", line 372, in _lazy_init\n",
      "    torch._C._cuda_init()\n",
      "RuntimeError: No CUDA GPUs are available\n",
      "\n",
      "The above exception was the direct cause of the following exception:\n",
      "\n",
      "\u001b[36mray::ClientAppActor.run()\u001b[39m (pid=1336571, ip=143.106.45.41, actor_id=447bc0f726f62603dbf37b8901000000, repr=<flwr.simulation.ray_transport.ray_actor.ClientAppActor object at 0x7eff661aa330>)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/arthur/miniconda3/envs/flwr/lib/python3.12/site-packages/flwr/simulation/ray_transport/ray_actor.py\", line 64, in run\n",
      "    raise ClientAppException(str(ex)) from ex\n",
      "flwr.client.client_app.ClientAppException: \n",
      "Exception ClientAppException occurred. Message: No CUDA GPUs are available\n",
      "\u001b[91mERROR \u001b[0m:     Traceback (most recent call last):\n",
      "  File \"/home/arthur/miniconda3/envs/flwr/lib/python3.12/site-packages/flwr/simulation/legacy_app.py\", line 361, in start_simulation\n",
      "    hist = run_fl(\n",
      "           ^^^^^^^\n",
      "  File \"/home/arthur/miniconda3/envs/flwr/lib/python3.12/site-packages/flwr/server/server.py\", line 492, in run_fl\n",
      "    hist, elapsed_time = server.fit(\n",
      "                         ^^^^^^^^^^^\n",
      "  File \"/home/arthur/miniconda3/envs/flwr/lib/python3.12/site-packages/flwr/server/server.py\", line 93, in fit\n",
      "    self.parameters = self._get_initial_parameters(server_round=0, timeout=timeout)\n",
      "                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/arthur/miniconda3/envs/flwr/lib/python3.12/site-packages/flwr/server/server.py\", line 284, in _get_initial_parameters\n",
      "    get_parameters_res = random_client.get_parameters(\n",
      "                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/arthur/miniconda3/envs/flwr/lib/python3.12/site-packages/flwr/simulation/ray_transport/ray_client_proxy.py\", line 170, in get_parameters\n",
      "    message_out = self._submit_job(message, timeout)\n",
      "                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/arthur/miniconda3/envs/flwr/lib/python3.12/site-packages/flwr/simulation/ray_transport/ray_client_proxy.py\", line 109, in _submit_job\n",
      "    raise ex\n",
      "  File \"/home/arthur/miniconda3/envs/flwr/lib/python3.12/site-packages/flwr/simulation/ray_transport/ray_client_proxy.py\", line 95, in _submit_job\n",
      "    out_mssg, updated_context = self.actor_pool.get_client_result(\n",
      "                                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/arthur/miniconda3/envs/flwr/lib/python3.12/site-packages/flwr/simulation/ray_transport/ray_actor.py\", line 401, in get_client_result\n",
      "    return self._fetch_future_result(cid)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/arthur/miniconda3/envs/flwr/lib/python3.12/site-packages/flwr/simulation/ray_transport/ray_actor.py\", line 282, in _fetch_future_result\n",
      "    res_cid, out_mssg, updated_context = ray.get(\n",
      "                                         ^^^^^^^^\n",
      "  File \"/home/arthur/miniconda3/envs/flwr/lib/python3.12/site-packages/ray/_private/auto_init_hook.py\", line 21, in auto_init_wrapper\n",
      "    return fn(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/arthur/miniconda3/envs/flwr/lib/python3.12/site-packages/ray/_private/client_mode_hook.py\", line 103, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/arthur/miniconda3/envs/flwr/lib/python3.12/site-packages/ray/_private/worker.py\", line 2639, in get\n",
      "    values, debugger_breakpoint = worker.get_objects(object_refs, timeout=timeout)\n",
      "                                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/arthur/miniconda3/envs/flwr/lib/python3.12/site-packages/ray/_private/worker.py\", line 864, in get_objects\n",
      "    raise value.as_instanceof_cause()\n",
      "ray.exceptions.RayTaskError(ClientAppException): \u001b[36mray::ClientAppActor.run()\u001b[39m (pid=1336571, ip=143.106.45.41, actor_id=447bc0f726f62603dbf37b8901000000, repr=<flwr.simulation.ray_transport.ray_actor.ClientAppActor object at 0x7eff661aa330>)\n",
      "                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/arthur/miniconda3/envs/flwr/lib/python3.12/site-packages/flwr/client/client_app.py\", line 144, in __call__\n",
      "    return self._call(message, context)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/arthur/miniconda3/envs/flwr/lib/python3.12/site-packages/flwr/client/client_app.py\", line 128, in ffn\n",
      "    out_message = handle_legacy_message_from_msgtype(\n",
      "                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/arthur/miniconda3/envs/flwr/lib/python3.12/site-packages/flwr/client/message_handler/message_handler.py\", line 96, in handle_legacy_message_from_msgtype\n",
      "    client = client_fn(context)\n",
      "             ^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/arthur/miniconda3/envs/flwr/lib/python3.12/site-packages/flwr/client/client_app.py\", line 72, in adaptor_fn\n",
      "    return client_fn(str(cid))  # type: ignore\n",
      "           ^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/tmp/ipykernel_1330781/2997288950.py\", line 126, in client_fn\n",
      "  File \"/home/arthur/miniconda3/envs/flwr/lib/python3.12/site-packages/torch/nn/modules/module.py\", line 1355, in to\n",
      "    return self._apply(convert)\n",
      "           ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/arthur/miniconda3/envs/flwr/lib/python3.12/site-packages/torch/nn/modules/module.py\", line 915, in _apply\n",
      "    module._apply(fn)\n",
      "  File \"/home/arthur/miniconda3/envs/flwr/lib/python3.12/site-packages/torch/nn/modules/module.py\", line 915, in _apply\n",
      "    module._apply(fn)\n",
      "  File \"/home/arthur/miniconda3/envs/flwr/lib/python3.12/site-packages/torch/nn/modules/module.py\", line 942, in _apply\n",
      "    param_applied = fn(param)\n",
      "                    ^^^^^^^^^\n",
      "  File \"/home/arthur/miniconda3/envs/flwr/lib/python3.12/site-packages/torch/nn/modules/module.py\", line 1341, in convert\n",
      "    return t.to(\n",
      "           ^^^^^\n",
      "  File \"/home/arthur/miniconda3/envs/flwr/lib/python3.12/site-packages/torch/cuda/__init__.py\", line 372, in _lazy_init\n",
      "    torch._C._cuda_init()\n",
      "RuntimeError: No CUDA GPUs are available\n",
      "\n",
      "The above exception was the direct cause of the following exception:\n",
      "\n",
      "\u001b[36mray::ClientAppActor.run()\u001b[39m (pid=1336571, ip=143.106.45.41, actor_id=447bc0f726f62603dbf37b8901000000, repr=<flwr.simulation.ray_transport.ray_actor.ClientAppActor object at 0x7eff661aa330>)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/arthur/miniconda3/envs/flwr/lib/python3.12/site-packages/flwr/simulation/ray_transport/ray_actor.py\", line 64, in run\n",
      "    raise ClientAppException(str(ex)) from ex\n",
      "flwr.client.client_app.ClientAppException: \n",
      "Exception ClientAppException occurred. Message: No CUDA GPUs are available\n",
      "\n",
      "\u001b[91mERROR \u001b[0m:     Your simulation crashed :(. This could be because of several reasons. The most common are: \n",
      "\t > Sometimes, issues in the simulation code itself can cause crashes. It's always a good idea to double-check your code for any potential bugs or inconsistencies that might be contributing to the problem. For example: \n",
      "\t\t - You might be using a class attribute in your clients that hasn't been defined.\n",
      "\t\t - There could be an incorrect method call to a 3rd party library (e.g., PyTorch).\n",
      "\t\t - The return types of methods in your clients/strategies might be incorrect.\n",
      "\t > Your system couldn't fit a single VirtualClient: try lowering `client_resources`.\n",
      "\t > All the actors in your pool crashed. This could be because: \n",
      "\t\t - You clients hit an out-of-memory (OOM) error and actors couldn't recover from it. Try launching your simulation with more generous `client_resources` setting (i.e. it seems {'num_cpus': 1, 'num_gpus': 0.0} is not enough for your run). Use fewer concurrent actors. \n",
      "\t\t - You were running a multi-node simulation and all worker nodes disconnected. The head node might still be alive but cannot accommodate any actor with resources: {'num_cpus': 1, 'num_gpus': 0.0}.\n",
      "Take a look at the Flower simulation examples for guidance <https://flower.ai/docs/framework/how-to-run-simulations.html>.\n",
      "\u001b[36m(ClientAppActor pid=1336571)\u001b[0m \u001b[93mWARNING \u001b[0m:   DEPRECATED FEATURE: `client_fn` now expects a signature `def client_fn(context: Context)`.The provided `client_fn` has signature: {'cid': <Parameter \"cid: str\">}. You can import the `Context` like this: `from flwr.common import Context`\n",
      "\u001b[36m(ClientAppActor pid=1336571)\u001b[0m \n",
      "\u001b[36m(ClientAppActor pid=1336571)\u001b[0m             This is a deprecated feature. It will be removed\n",
      "\u001b[36m(ClientAppActor pid=1336571)\u001b[0m             entirely in future versions of Flower.\n",
      "\u001b[36m(ClientAppActor pid=1336571)\u001b[0m         \n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "Simulation crashed.",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mRayTaskError(ClientAppException)\u001b[39m          Traceback (most recent call last)",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/envs/flwr/lib/python3.12/site-packages/flwr/simulation/legacy_app.py:361\u001b[39m, in \u001b[36mstart_simulation\u001b[39m\u001b[34m(client_fn, num_clients, clients_ids, client_resources, server, config, strategy, client_manager, ray_init_args, keep_initialised, actor_type, actor_kwargs, actor_scheduling)\u001b[39m\n\u001b[32m    359\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m    360\u001b[39m     \u001b[38;5;66;03m# Start training\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m361\u001b[39m     hist = \u001b[43mrun_fl\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    362\u001b[39m \u001b[43m        \u001b[49m\u001b[43mserver\u001b[49m\u001b[43m=\u001b[49m\u001b[43minitialized_server\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    363\u001b[39m \u001b[43m        \u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m=\u001b[49m\u001b[43minitialized_config\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    364\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    365\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m ex:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/envs/flwr/lib/python3.12/site-packages/flwr/server/server.py:492\u001b[39m, in \u001b[36mrun_fl\u001b[39m\u001b[34m(server, config)\u001b[39m\n\u001b[32m    491\u001b[39m \u001b[38;5;250m\u001b[39m\u001b[33;03m\"\"\"Train a model on the given server and return the History object.\"\"\"\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m492\u001b[39m hist, elapsed_time = \u001b[43mserver\u001b[49m\u001b[43m.\u001b[49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    493\u001b[39m \u001b[43m    \u001b[49m\u001b[43mnum_rounds\u001b[49m\u001b[43m=\u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m.\u001b[49m\u001b[43mnum_rounds\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m=\u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m.\u001b[49m\u001b[43mround_timeout\u001b[49m\n\u001b[32m    494\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    496\u001b[39m log(INFO, \u001b[33m\"\u001b[39m\u001b[33m\"\u001b[39m)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/envs/flwr/lib/python3.12/site-packages/flwr/server/server.py:93\u001b[39m, in \u001b[36mServer.fit\u001b[39m\u001b[34m(self, num_rounds, timeout)\u001b[39m\n\u001b[32m     92\u001b[39m log(INFO, \u001b[33m\"\u001b[39m\u001b[33m[INIT]\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m---> \u001b[39m\u001b[32m93\u001b[39m \u001b[38;5;28mself\u001b[39m.parameters = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_get_initial_parameters\u001b[49m\u001b[43m(\u001b[49m\u001b[43mserver_round\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m0\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     94\u001b[39m log(INFO, \u001b[33m\"\u001b[39m\u001b[33mStarting evaluation of initial global parameters\u001b[39m\u001b[33m\"\u001b[39m)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/envs/flwr/lib/python3.12/site-packages/flwr/server/server.py:284\u001b[39m, in \u001b[36mServer._get_initial_parameters\u001b[39m\u001b[34m(self, server_round, timeout)\u001b[39m\n\u001b[32m    283\u001b[39m ins = GetParametersIns(config={})\n\u001b[32m--> \u001b[39m\u001b[32m284\u001b[39m get_parameters_res = \u001b[43mrandom_client\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget_parameters\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    285\u001b[39m \u001b[43m    \u001b[49m\u001b[43mins\u001b[49m\u001b[43m=\u001b[49m\u001b[43mins\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgroup_id\u001b[49m\u001b[43m=\u001b[49m\u001b[43mserver_round\u001b[49m\n\u001b[32m    286\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    287\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m get_parameters_res.status.code == Code.OK:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/envs/flwr/lib/python3.12/site-packages/flwr/simulation/ray_transport/ray_client_proxy.py:170\u001b[39m, in \u001b[36mRayActorClientProxy.get_parameters\u001b[39m\u001b[34m(self, ins, timeout, group_id)\u001b[39m\n\u001b[32m    163\u001b[39m message = \u001b[38;5;28mself\u001b[39m._wrap_recorddict_in_message(\n\u001b[32m    164\u001b[39m     recorddict,\n\u001b[32m    165\u001b[39m     message_type=MessageTypeLegacy.GET_PARAMETERS,\n\u001b[32m    166\u001b[39m     timeout=timeout,\n\u001b[32m    167\u001b[39m     group_id=group_id,\n\u001b[32m    168\u001b[39m )\n\u001b[32m--> \u001b[39m\u001b[32m170\u001b[39m message_out = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_submit_job\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmessage\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    172\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m recorddict_to_getparametersres(message_out.content, keep_input=\u001b[38;5;28;01mFalse\u001b[39;00m)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/envs/flwr/lib/python3.12/site-packages/flwr/simulation/ray_transport/ray_client_proxy.py:109\u001b[39m, in \u001b[36mRayActorClientProxy._submit_job\u001b[39m\u001b[34m(self, message, timeout)\u001b[39m\n\u001b[32m    108\u001b[39m     log(ERROR, ex)\n\u001b[32m--> \u001b[39m\u001b[32m109\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m ex\n\u001b[32m    111\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m out_mssg\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/envs/flwr/lib/python3.12/site-packages/flwr/simulation/ray_transport/ray_client_proxy.py:95\u001b[39m, in \u001b[36mRayActorClientProxy._submit_job\u001b[39m\u001b[34m(self, message, timeout)\u001b[39m\n\u001b[32m     89\u001b[39m \u001b[38;5;28mself\u001b[39m.actor_pool.submit_client_job(\n\u001b[32m     90\u001b[39m     \u001b[38;5;28;01mlambda\u001b[39;00m a, a_fn, mssg, partition_id, context: a.run.remote(\n\u001b[32m     91\u001b[39m         a_fn, mssg, partition_id, context\n\u001b[32m     92\u001b[39m     ),\n\u001b[32m     93\u001b[39m     (\u001b[38;5;28mself\u001b[39m.app_fn, message, partition_id_str, context),\n\u001b[32m     94\u001b[39m )\n\u001b[32m---> \u001b[39m\u001b[32m95\u001b[39m out_mssg, updated_context = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mactor_pool\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget_client_result\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m     96\u001b[39m \u001b[43m    \u001b[49m\u001b[43mpartition_id_str\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtimeout\u001b[49m\n\u001b[32m     97\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     99\u001b[39m \u001b[38;5;66;03m# Update state\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/envs/flwr/lib/python3.12/site-packages/flwr/simulation/ray_transport/ray_actor.py:401\u001b[39m, in \u001b[36mVirtualClientEngineActorPool.get_client_result\u001b[39m\u001b[34m(self, cid, timeout)\u001b[39m\n\u001b[32m    399\u001b[39m \u001b[38;5;66;03m# Fetch result belonging to the VirtualClient calling this method\u001b[39;00m\n\u001b[32m    400\u001b[39m \u001b[38;5;66;03m# Return both result from tasks and (potentially) updated run context\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m401\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_fetch_future_result\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcid\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/envs/flwr/lib/python3.12/site-packages/flwr/simulation/ray_transport/ray_actor.py:282\u001b[39m, in \u001b[36mVirtualClientEngineActorPool._fetch_future_result\u001b[39m\u001b[34m(self, cid)\u001b[39m\n\u001b[32m    281\u001b[39m     future: ObjectRef[Any] = \u001b[38;5;28mself\u001b[39m._cid_to_future[cid][\u001b[33m\"\u001b[39m\u001b[33mfuture\u001b[39m\u001b[33m\"\u001b[39m]  \u001b[38;5;66;03m# type: ignore\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m282\u001b[39m     res_cid, out_mssg, updated_context = \u001b[43mray\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    283\u001b[39m \u001b[43m        \u001b[49m\u001b[43mfuture\u001b[49m\n\u001b[32m    284\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# type: (str, Message, Context)\u001b[39;00m\n\u001b[32m    285\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m ray.exceptions.RayActorError \u001b[38;5;28;01mas\u001b[39;00m ex:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/envs/flwr/lib/python3.12/site-packages/ray/_private/auto_init_hook.py:21\u001b[39m, in \u001b[36mwrap_auto_init.<locals>.auto_init_wrapper\u001b[39m\u001b[34m(*args, **kwargs)\u001b[39m\n\u001b[32m     20\u001b[39m auto_init_ray()\n\u001b[32m---> \u001b[39m\u001b[32m21\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/envs/flwr/lib/python3.12/site-packages/ray/_private/client_mode_hook.py:103\u001b[39m, in \u001b[36mclient_mode_hook.<locals>.wrapper\u001b[39m\u001b[34m(*args, **kwargs)\u001b[39m\n\u001b[32m    102\u001b[39m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mgetattr\u001b[39m(ray, func.\u001b[34m__name__\u001b[39m)(*args, **kwargs)\n\u001b[32m--> \u001b[39m\u001b[32m103\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/envs/flwr/lib/python3.12/site-packages/ray/_private/worker.py:2639\u001b[39m, in \u001b[36mget\u001b[39m\u001b[34m(object_refs, timeout)\u001b[39m\n\u001b[32m   2638\u001b[39m \u001b[38;5;66;03m# TODO(ujvl): Consider how to allow user to retrieve the ready objects.\u001b[39;00m\n\u001b[32m-> \u001b[39m\u001b[32m2639\u001b[39m values, debugger_breakpoint = \u001b[43mworker\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget_objects\u001b[49m\u001b[43m(\u001b[49m\u001b[43mobject_refs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   2640\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m i, value \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(values):\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/envs/flwr/lib/python3.12/site-packages/ray/_private/worker.py:864\u001b[39m, in \u001b[36mWorker.get_objects\u001b[39m\u001b[34m(self, object_refs, timeout)\u001b[39m\n\u001b[32m    863\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(value, RayTaskError):\n\u001b[32m--> \u001b[39m\u001b[32m864\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m value.as_instanceof_cause()\n\u001b[32m    865\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "\u001b[31mRayTaskError(ClientAppException)\u001b[39m: \u001b[36mray::ClientAppActor.run()\u001b[39m (pid=1336571, ip=143.106.45.41, actor_id=447bc0f726f62603dbf37b8901000000, repr=<flwr.simulation.ray_transport.ray_actor.ClientAppActor object at 0x7eff661aa330>)\n                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/home/arthur/miniconda3/envs/flwr/lib/python3.12/site-packages/flwr/client/client_app.py\", line 144, in __call__\n    return self._call(message, context)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/home/arthur/miniconda3/envs/flwr/lib/python3.12/site-packages/flwr/client/client_app.py\", line 128, in ffn\n    out_message = handle_legacy_message_from_msgtype(\n                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/home/arthur/miniconda3/envs/flwr/lib/python3.12/site-packages/flwr/client/message_handler/message_handler.py\", line 96, in handle_legacy_message_from_msgtype\n    client = client_fn(context)\n             ^^^^^^^^^^^^^^^^^^\n  File \"/home/arthur/miniconda3/envs/flwr/lib/python3.12/site-packages/flwr/client/client_app.py\", line 72, in adaptor_fn\n    return client_fn(str(cid))  # type: ignore\n           ^^^^^^^^^^^^^^^^^^^\n  File \"/tmp/ipykernel_1330781/2997288950.py\", line 126, in client_fn\n  File \"/home/arthur/miniconda3/envs/flwr/lib/python3.12/site-packages/torch/nn/modules/module.py\", line 1355, in to\n    return self._apply(convert)\n           ^^^^^^^^^^^^^^^^^^^^\n  File \"/home/arthur/miniconda3/envs/flwr/lib/python3.12/site-packages/torch/nn/modules/module.py\", line 915, in _apply\n    module._apply(fn)\n  File \"/home/arthur/miniconda3/envs/flwr/lib/python3.12/site-packages/torch/nn/modules/module.py\", line 915, in _apply\n    module._apply(fn)\n  File \"/home/arthur/miniconda3/envs/flwr/lib/python3.12/site-packages/torch/nn/modules/module.py\", line 942, in _apply\n    param_applied = fn(param)\n                    ^^^^^^^^^\n  File \"/home/arthur/miniconda3/envs/flwr/lib/python3.12/site-packages/torch/nn/modules/module.py\", line 1341, in convert\n    return t.to(\n           ^^^^^\n  File \"/home/arthur/miniconda3/envs/flwr/lib/python3.12/site-packages/torch/cuda/__init__.py\", line 372, in _lazy_init\n    torch._C._cuda_init()\nRuntimeError: No CUDA GPUs are available\n\nThe above exception was the direct cause of the following exception:\n\n\u001b[36mray::ClientAppActor.run()\u001b[39m (pid=1336571, ip=143.106.45.41, actor_id=447bc0f726f62603dbf37b8901000000, repr=<flwr.simulation.ray_transport.ray_actor.ClientAppActor object at 0x7eff661aa330>)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/home/arthur/miniconda3/envs/flwr/lib/python3.12/site-packages/flwr/simulation/ray_transport/ray_actor.py\", line 64, in run\n    raise ClientAppException(str(ex)) from ex\nflwr.client.client_app.ClientAppException: \nException ClientAppException occurred. Message: No CUDA GPUs are available",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[31mRuntimeError\u001b[39m                              Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[5]\u001b[39m\u001b[32m, line 149\u001b[39m\n\u001b[32m    142\u001b[39m strategy = fl.server.strategy.FedAvg(\n\u001b[32m    143\u001b[39m     fraction_fit=\u001b[32m1.0\u001b[39m,  \u001b[38;5;66;03m# Usar 100% dos clientes para treino em cada rodada\u001b[39;00m\n\u001b[32m    144\u001b[39m     min_fit_clients=NUM_CLIENTS,\n\u001b[32m    145\u001b[39m     min_available_clients=NUM_CLIENTS,\n\u001b[32m    146\u001b[39m )\n\u001b[32m    148\u001b[39m \u001b[38;5;66;03m# Iniciar a simulação\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m149\u001b[39m \u001b[43mfl\u001b[49m\u001b[43m.\u001b[49m\u001b[43msimulation\u001b[49m\u001b[43m.\u001b[49m\u001b[43mstart_simulation\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    150\u001b[39m \u001b[43m    \u001b[49m\u001b[43mclient_fn\u001b[49m\u001b[43m=\u001b[49m\u001b[43mclient_fn\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    151\u001b[39m \u001b[43m    \u001b[49m\u001b[43mnum_clients\u001b[49m\u001b[43m=\u001b[49m\u001b[43mNUM_CLIENTS\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    152\u001b[39m \u001b[43m    \u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m=\u001b[49m\u001b[43mfl\u001b[49m\u001b[43m.\u001b[49m\u001b[43mserver\u001b[49m\u001b[43m.\u001b[49m\u001b[43mServerConfig\u001b[49m\u001b[43m(\u001b[49m\u001b[43mnum_rounds\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m3\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    153\u001b[39m \u001b[43m    \u001b[49m\u001b[43mstrategy\u001b[49m\u001b[43m=\u001b[49m\u001b[43mstrategy\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    154\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/envs/flwr/lib/python3.12/site-packages/flwr/simulation/legacy_app.py:397\u001b[39m, in \u001b[36mstart_simulation\u001b[39m\u001b[34m(client_fn, num_clients, clients_ids, client_resources, server, config, strategy, client_manager, ray_init_args, keep_initialised, actor_type, actor_kwargs, actor_scheduling)\u001b[39m\n\u001b[32m    367\u001b[39m     log(ERROR, traceback.format_exc())\n\u001b[32m    368\u001b[39m     log(\n\u001b[32m    369\u001b[39m         ERROR,\n\u001b[32m    370\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mYour simulation crashed :(. This could be because of several reasons. \u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m   (...)\u001b[39m\u001b[32m    395\u001b[39m         client_resources,\n\u001b[32m    396\u001b[39m     )\n\u001b[32m--> \u001b[39m\u001b[32m397\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\u001b[33m\"\u001b[39m\u001b[33mSimulation crashed.\u001b[39m\u001b[33m\"\u001b[39m) \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mex\u001b[39;00m\n\u001b[32m    399\u001b[39m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[32m    400\u001b[39m     \u001b[38;5;66;03m# Stop time monitoring resources in cluster\u001b[39;00m\n\u001b[32m    401\u001b[39m     f_stop.set()\n",
      "\u001b[31mRuntimeError\u001b[39m: Simulation crashed."
     ]
    }
   ],
   "source": [
    "# Desativar um aviso comum do Matplotlib no MedMNIST\n",
    "warnings.filterwarnings(\"ignore\", category=UserWarning)\n",
    "DEVICE = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "# 1. Definição do Modelo (uma CNN simples)\n",
    "class Net(nn.Module):\n",
    "    def __init__(self, in_channels=1, num_classes=11):\n",
    "        super(Net, self).__init__()\n",
    "        self.layer1 = nn.Sequential(\n",
    "            nn.Conv3d(in_channels, 16, kernel_size=3),\n",
    "            nn.BatchNorm3d(16),\n",
    "            nn.ReLU())\n",
    "        self.layer2 = nn.Sequential(\n",
    "            nn.Conv3d(16, 16, kernel_size=3),\n",
    "            nn.BatchNorm3d(16),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(kernel_size=2, stride=2))\n",
    "        self.layer3 = nn.Sequential(\n",
    "            nn.Conv3d(16, 64, kernel_size=3),\n",
    "            nn.BatchNorm3d(64),\n",
    "            nn.ReLU())\n",
    "        self.layer4 = nn.Sequential(\n",
    "            nn.Conv3d(64, 64, kernel_size=3),\n",
    "            nn.BatchNorm3d(64),\n",
    "            nn.ReLU())\n",
    "        self.layer5 = nn.Sequential(\n",
    "            nn.Conv3d(64, 64, kernel_size=3, padding=1),\n",
    "            nn.BatchNorm3d(64),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool3d(kernel_size=2, stride=2))\n",
    "        self.fc = nn.Sequential(\n",
    "            nn.Linear(64 * 4 * 4, 128),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(128, 128),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(128, num_classes))\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.layer1(x)\n",
    "        x = self.layer2(x)\n",
    "        x = self.layer3(x)\n",
    "        x = self.layer4(x)\n",
    "        x = self.layer5(x)\n",
    "        x = x.view(x.size(0), -1)\n",
    "        x = self.fc(x)\n",
    "        return x\n",
    "\n",
    "# 2. Funções de Treino e Teste (padrão)\n",
    "def train(net, trainloader, epochs):\n",
    "    criterion = torch.nn.CrossEntropyLoss()\n",
    "    optimizer = torch.optim.SGD(net.parameters(), lr=0.001, momentum=0.9)\n",
    "    for _ in range(epochs):\n",
    "        for images, labels in trainloader:\n",
    "            optimizer.zero_grad()\n",
    "            criterion(net(images.to(DEVICE)), labels.squeeze().long().to(DEVICE)).backward()\n",
    "            optimizer.step()\n",
    "\n",
    "def test(net, testloader):\n",
    "    criterion = torch.nn.CrossEntropyLoss()\n",
    "    correct, total, loss = 0, 0, 0.0\n",
    "    with torch.no_grad():\n",
    "        for images, labels in testloader:\n",
    "            outputs = net(images.to(DEVICE))\n",
    "            labels = labels.squeeze().long().to(DEVICE)\n",
    "            loss += criterion(outputs, labels).item()\n",
    "            total += labels.size(0)\n",
    "            correct += (torch.max(outputs.data, 1)[1] == labels).sum().item()\n",
    "    return loss / len(testloader.dataset), correct / total\n",
    "\n",
    "# 3. Preparação e Particionamento dos Dados (A PARTE MAIS IMPORTANTE)\n",
    "def load_data(num_partitions):\n",
    "    # Transformações para o dataset\n",
    "    data_transform = transforms.Compose([ToTensor()])\n",
    "    \n",
    "    # Carregar o dataset de treino completo do MedMNIST\n",
    "    full_train_dataset = OrganMNIST3D(split=\"train\", transform=data_transform, download=True)\n",
    "\n",
    "    # Calcular o tamanho de cada partição\n",
    "    num_images = len(full_train_dataset)\n",
    "    partition_size = num_images // num_partitions\n",
    "    lengths = [partition_size] * num_partitions\n",
    "    remainder = num_images % num_partitions\n",
    "    for i in range(remainder):\n",
    "        lengths[i] += 1\n",
    "    \n",
    "    # Usar a função do PyTorch para dividir o dataset em partições não sobrepostas\n",
    "    # Esta é a alternativa ao Partitioner do Flower\n",
    "    partitions = random_split(full_train_dataset, lengths)\n",
    "\n",
    "    # Criar um DataLoader para cada partição\n",
    "    train_loaders = [DataLoader(part, batch_size=32, shuffle=True) for part in partitions]\n",
    "    \n",
    "    # Carregar o dataset de teste (geralmente é centralizado e não particionado)\n",
    "    test_loader = DataLoader(OrganMNIST3D(split=\"test\", download=True), batch_size=32)\n",
    "    \n",
    "    return train_loaders, test_loader\n",
    "\n",
    "# 4. Definição do Cliente Flower\n",
    "class FlowerClient(fl.client.NumPyClient):\n",
    "    def __init__(self, model, trainloader, testloader):\n",
    "        self.model = model\n",
    "        self.trainloader = trainloader\n",
    "        self.testloader = testloader\n",
    "\n",
    "    def get_parameters(self, config):\n",
    "        return [val.cpu().numpy() for _, val in self.model.state_dict().items()]\n",
    "\n",
    "    def set_parameters(self, parameters):\n",
    "        params_dict = zip(self.model.state_dict().keys(), parameters)\n",
    "        state_dict = OrderedDict({k: torch.tensor(v) for k, v in params_dict})\n",
    "        self.model.load_state_dict(state_dict, strict=True)\n",
    "\n",
    "    def fit(self, parameters, config):\n",
    "        self.set_parameters(parameters)\n",
    "        train(self.model, self.trainloader, epochs=1)\n",
    "        return self.get_parameters(config={}), len(self.trainloader.dataset), {}\n",
    "\n",
    "    def evaluate(self, parameters, config):\n",
    "        self.set_parameters(parameters)\n",
    "        loss, accuracy = test(self.model, self.testloader)\n",
    "        return float(loss), len(self.testloader.dataset), {\"accuracy\": float(accuracy)}\n",
    "\n",
    "# 5. Função para criar clientes (client_fn)\n",
    "def client_fn(cid: str) -> FlowerClient:\n",
    "    \"\"\"Cria um Flower client para um dado client ID.\"\"\"\n",
    "    model = Net().to(DEVICE)\n",
    "    # Cada cliente recebe seu próprio DataLoader de treino\n",
    "    train_loader = train_loaders[int(cid)]\n",
    "    # O testloader pode ser compartilhado\n",
    "    test_loader = test_loader_global\n",
    "    \n",
    "    return FlowerClient(model, train_loader, test_loader)\n",
    "\n",
    "# 6. Início da Simulação\n",
    "if __name__ == \"__main__\":\n",
    "    NUM_CLIENTS = 10\n",
    "    \n",
    "    # Carregar e particionar os dados ANTES da simulação\n",
    "    train_loaders, test_loader_global = load_data(num_partitions=NUM_CLIENTS)\n",
    "\n",
    "    # Definir a estratégia de agregação (FedAvg)\n",
    "    strategy = fl.server.strategy.FedAvg(\n",
    "        fraction_fit=1.0,  # Usar 100% dos clientes para treino em cada rodada\n",
    "        min_fit_clients=NUM_CLIENTS,\n",
    "        min_available_clients=NUM_CLIENTS,\n",
    "    )\n",
    "\n",
    "    # Iniciar a simulação\n",
    "    fl.simulation.start_simulation(\n",
    "        client_fn=client_fn,\n",
    "        num_clients=NUM_CLIENTS,\n",
    "        config=fl.server.ServerConfig(num_rounds=3),\n",
    "        strategy=strategy,\n",
    "    )"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "flwr",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
