{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f5e9b472",
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import OrderedDict\n",
    "import warnings\n",
    "from typing import Dict, List, Optional, Tuple\n",
    "\n",
    "import flwr as fl\n",
    "from flwr.common import ndarrays_to_parameters, NDArrays, Scalar, Context\n",
    "from flwr.client import Client, ClientApp, NumPyClient\n",
    "from flwr.server import ServerApp, ServerConfig, ServerAppComponents\n",
    "from flwr.server.strategy import FedAvg, FedAdagrad\n",
    "from flwr.simulation import run_simulation\n",
    "\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import DataLoader, random_split\n",
    "from torchvision.transforms import transforms\n",
    "\n",
    "# Importar o MedMNIST\n",
    "from medmnist import OrganMNIST3D"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "682c4ca9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Desativar um aviso comum do Matplotlib no MedMNIST\n",
    "warnings.filterwarnings(\"ignore\", category=UserWarning)\n",
    "DEVICE = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9b054fb6",
   "metadata": {},
   "outputs": [],
   "source": [
    "NUM_PARTITIONS = 3\n",
    "BATCH_SIZE = 32"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8448f614",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Torch ToTensor() não lida com imagens volumétricas\n",
    "class ToTensor:\n",
    "    def __call__(self, x):\n",
    "        return torch.from_numpy(x).float()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "60a79a24",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. Definição do Modelo (uma CNN simples)\n",
    "class Net(nn.Module):\n",
    "    def __init__(self, in_channels=1, num_classes=11):\n",
    "        super(Net, self).__init__()\n",
    "        self.layer1 = nn.Sequential(\n",
    "            nn.Conv3d(in_channels, 16, kernel_size=3),\n",
    "            nn.BatchNorm3d(16),\n",
    "            nn.ReLU())\n",
    "        self.layer2 = nn.Sequential(\n",
    "            nn.Conv3d(16, 16, kernel_size=3),\n",
    "            nn.BatchNorm3d(16),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool3d(kernel_size=2, stride=2))\n",
    "        self.layer3 = nn.Sequential(\n",
    "            nn.Conv3d(16, 64, kernel_size=3),\n",
    "            nn.BatchNorm3d(64),\n",
    "            nn.ReLU())\n",
    "        self.layer4 = nn.Sequential(\n",
    "            nn.Conv3d(64, 64, kernel_size=3),\n",
    "            nn.BatchNorm3d(64),\n",
    "            nn.ReLU())\n",
    "        self.layer5 = nn.Sequential(\n",
    "            nn.Conv3d(64, 64, kernel_size=3, padding=1),\n",
    "            nn.BatchNorm3d(64),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool3d(kernel_size=2, stride=2))\n",
    "        self.fc = nn.Sequential(\n",
    "            nn.Linear(64 * 4**3, 128),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(128, 128),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(128, num_classes))\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.layer1(x)\n",
    "        x = self.layer2(x)\n",
    "        x = self.layer3(x)\n",
    "        x = self.layer4(x)\n",
    "        x = self.layer5(x)\n",
    "        x = x.view(x.size(0), -1)\n",
    "        x = self.fc(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "8c6934af",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2. Funções de Treino e Teste (padrão)\n",
    "def train(net, trainloader, epochs):\n",
    "    criterion = torch.nn.CrossEntropyLoss()\n",
    "    # optimizer = torch.optim.SGD(net.parameters(), lr=0.1e-5, momentum=0.9)\n",
    "    optimizer = torch.optim.Adam(net.parameters(), lr=1e-4)\n",
    "    net.train()\n",
    "    for _ in range(epochs):\n",
    "        for images, labels in trainloader:\n",
    "            optimizer.zero_grad()\n",
    "            images, labels = images.to(DEVICE), labels.to(DEVICE)\n",
    "            output = net(images)\n",
    "            loss = criterion(output, labels.long().squeeze(dim=1))\n",
    "            loss.backward()\n",
    "            optimizer.step()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "31df7b76",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def test(net, testloader):\n",
    "    criterion = torch.nn.CrossEntropyLoss()\n",
    "    correct, total, loss = 0, 0, 0.0\n",
    "    with torch.no_grad():\n",
    "        for images, labels in testloader:\n",
    "            images, labels = images.cuda().float(), labels.cuda().long()\n",
    "            outputs = net(images)\n",
    "            labels = labels.squeeze()\n",
    "            loss += criterion(outputs, labels).item()\n",
    "            total += labels.size(0)\n",
    "            correct += (torch.max(outputs.data, 1)[1] == labels).sum().item()\n",
    "    return loss / len(testloader.dataset), correct / total"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "388b4675",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3. Preparação e Particionamento dos Dados (A PARTE MAIS IMPORTANTE)\n",
    "def load_data(partition_id: int, num_partitions: int):\n",
    "    # Transformações para o dataset\n",
    "    data_transform = transforms.Compose([ToTensor()])\n",
    "    \n",
    "    # Carregar o dataset de treino completo do MedMNIST\n",
    "    full_train_dataset = OrganMNIST3D(split=\"train\", transform=data_transform, download=True)\n",
    "    full_val_dataset = OrganMNIST3D(split=\"val\", transform=data_transform, download=True)\n",
    "\n",
    "    def partition_data(data):\n",
    "        num_images = len(data)\n",
    "        partition_size = num_images // num_partitions\n",
    "        lengths = [partition_size] * num_partitions\n",
    "        # Caso divisão não exata\n",
    "        remainder = num_images % num_partitions\n",
    "        for i in range(remainder):\n",
    "            lengths[i] += 1\n",
    "        return lengths\n",
    "\n",
    "    train_lengths = partition_data(full_train_dataset)\n",
    "    val_lengths = partition_data(full_val_dataset)\n",
    "\n",
    "    # Usar a função do PyTorch para dividir o dataset em partições não sobrepostas\n",
    "    # Esta é a alternativa ao Partitioner do Flower\n",
    "    # random_split não deve gerar amostras únicas para um mesmo cliente, necessário verificar\n",
    "    train_partitions = random_split(full_train_dataset, train_lengths)\n",
    "    val_partitions = random_split(full_val_dataset, val_lengths)\n",
    "\n",
    "    # Criar um DataLoader para cada partição\n",
    "    train_loaders = [DataLoader(part, batch_size=32, shuffle=True) for part in train_partitions]\n",
    "    val_loaders = [DataLoader(part, batch_size=32, shuffle=True) for part in val_partitions]\n",
    "    \n",
    "    # Carregar o dataset de teste (geralmente é centralizado e não particionado)\n",
    "    test_loader = DataLoader(OrganMNIST3D(split=\"test\", download=True), batch_size=32)\n",
    "\n",
    "    return train_loaders[partition_id], val_loaders[partition_id], test_loader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "9b1cf6fc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train samples: 971\n",
      "Val samples: 161\n",
      "Test samples: 610\n"
     ]
    }
   ],
   "source": [
    "trainloader, valloader, testloader = load_data(0, 1)\n",
    "print(f\"Train samples: {sum([len(trainloader.dataset)])}\")\n",
    "print(f\"Val samples: {sum([len(valloader.dataset)])}\")\n",
    "print(f\"Test samples: {len(testloader.dataset)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "aec089b1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train samples: 486\n",
      "Val samples: 81\n",
      "Test samples: 610\n"
     ]
    }
   ],
   "source": [
    "trainloader, valloader, testloader = load_data(0, 2)\n",
    "print(f\"Train samples: {sum([len(trainloader.dataset)])}\")\n",
    "print(f\"Val samples: {sum([len(valloader.dataset)])}\")\n",
    "print(f\"Test samples: {len(testloader.dataset)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "e3accbe2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_parameters(net) -> List[np.ndarray]:\n",
    "    return [val.cpu().numpy() for _, val in net.state_dict().items()]\n",
    "\n",
    "def set_parameters(net, parameters: List[np.ndarray]):\n",
    "    params_dict = zip(net.state_dict().keys(), parameters)\n",
    "    state_dict = OrderedDict({k: torch.tensor(v) for k, v in params_dict})\n",
    "    net.load_state_dict(state_dict, strict=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "17b4bb7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 4. Definição do Cliente Flower\n",
    "class FlowerClient(NumPyClient):\n",
    "    def __init__(self, net, trainloader, testloader):\n",
    "        self.net = net\n",
    "        self.trainloader = trainloader\n",
    "        self.testloader = testloader\n",
    "\n",
    "    def get_parameters(self, config):\n",
    "        return get_parameters(self.net)\n",
    "\n",
    "    def fit(self, parameters, config):\n",
    "        set_parameters(self.net, parameters)\n",
    "        train(self.net, self.trainloader, epochs=1)\n",
    "        return get_parameters(self.net), len(self.trainloader.dataset), {}\n",
    "\n",
    "    def evaluate(self, parameters, config):\n",
    "        set_parameters(self.net, parameters)\n",
    "        loss, accuracy = test(self.net, self.testloader)\n",
    "        return float(loss), len(self.testloader.dataset), {\"accuracy\": float(accuracy)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "dfbcb714",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 5. Função para criar clientes (client_fn)\n",
    "def client_fn(context: Context) -> Client:\n",
    "    \"\"\"Cria um Flower client para um dado client ID.\"\"\"\n",
    "    net = Net().to(DEVICE)\n",
    "    # Cada cliente recebe seu próprio DataLoader de treino\n",
    "    partition_id = context.node_config['partition-id']\n",
    "    num_partitions = context.node_config['num-partitions']\n",
    "\n",
    "    train_loader, val_loader, _ = load_data(partition_id=partition_id, num_partitions=num_partitions)\n",
    "    \n",
    "    return FlowerClient(net, train_loader, val_loader).to_client()\n",
    "\n",
    "client = ClientApp(client_fn=client_fn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "7cd3beb3",
   "metadata": {},
   "outputs": [],
   "source": [
    "params = get_parameters(Net())\n",
    "def server_fn(context: Context) -> ServerAppComponents:\n",
    "    strategy = FedAvg(\n",
    "        fraction_fit = 0.3,\n",
    "        fraction_evaluate = 0.3,\n",
    "        min_fit_clients = 3,\n",
    "        min_evaluate_clients = 3,\n",
    "        min_available_clients = NUM_PARTITIONS,\n",
    "        initial_parameters = ndarrays_to_parameters(params),\n",
    "    )\n",
    "    config = ServerConfig(num_rounds=10)\n",
    "    return ServerAppComponents(strategy=strategy, config=config)\n",
    "\n",
    "server = ServerApp(server_fn=server_fn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "abda860a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 6. Início da Simulação\n",
    "NUM_CLIENTS = 3\n",
    "\n",
    "backend_config = {\"client_resources\": None}\n",
    "if DEVICE.type == \"cuda\":\n",
    "    backend_config = {\"client_resources\": {\"num_cpus\": 1, \"num_gpus\": 1}}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "eb8b33fc",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92mINFO \u001b[0m:      Starting Flower ServerApp, config: num_rounds=10, no round_timeout\n",
      "\u001b[92mINFO \u001b[0m:      \n",
      "\u001b[92mINFO \u001b[0m:      [INIT]\n",
      "\u001b[92mINFO \u001b[0m:      Using initial global parameters provided by strategy\n",
      "\u001b[92mINFO \u001b[0m:      Starting evaluation of initial global parameters\n",
      "\u001b[92mINFO \u001b[0m:      Evaluation returned no results (`None`)\n",
      "\u001b[92mINFO \u001b[0m:      \n",
      "\u001b[92mINFO \u001b[0m:      [ROUND 1]\n",
      "\u001b[92mINFO \u001b[0m:      configure_fit: strategy sampled 3 clients (out of 3)\n",
      "\u001b[92mINFO \u001b[0m:      aggregate_fit: received 3 results and 0 failures\n",
      "\u001b[93mWARNING \u001b[0m:   No fit_metrics_aggregation_fn provided\n",
      "\u001b[92mINFO \u001b[0m:      configure_evaluate: strategy sampled 3 clients (out of 3)\n",
      "\u001b[92mINFO \u001b[0m:      aggregate_evaluate: received 3 results and 0 failures\n",
      "\u001b[93mWARNING \u001b[0m:   No evaluate_metrics_aggregation_fn provided\n",
      "\u001b[92mINFO \u001b[0m:      \n",
      "\u001b[92mINFO \u001b[0m:      [ROUND 2]\n",
      "\u001b[92mINFO \u001b[0m:      configure_fit: strategy sampled 3 clients (out of 3)\n",
      "\u001b[92mINFO \u001b[0m:      aggregate_fit: received 3 results and 0 failures\n",
      "\u001b[92mINFO \u001b[0m:      configure_evaluate: strategy sampled 3 clients (out of 3)\n",
      "\u001b[92mINFO \u001b[0m:      aggregate_evaluate: received 3 results and 0 failures\n",
      "\u001b[92mINFO \u001b[0m:      \n",
      "\u001b[92mINFO \u001b[0m:      [ROUND 3]\n",
      "\u001b[92mINFO \u001b[0m:      configure_fit: strategy sampled 3 clients (out of 3)\n",
      "\u001b[92mINFO \u001b[0m:      aggregate_fit: received 3 results and 0 failures\n",
      "\u001b[92mINFO \u001b[0m:      configure_evaluate: strategy sampled 3 clients (out of 3)\n",
      "\u001b[92mINFO \u001b[0m:      aggregate_evaluate: received 3 results and 0 failures\n",
      "\u001b[92mINFO \u001b[0m:      \n",
      "\u001b[92mINFO \u001b[0m:      [ROUND 4]\n",
      "\u001b[92mINFO \u001b[0m:      configure_fit: strategy sampled 3 clients (out of 3)\n",
      "\u001b[92mINFO \u001b[0m:      aggregate_fit: received 3 results and 0 failures\n",
      "\u001b[92mINFO \u001b[0m:      configure_evaluate: strategy sampled 3 clients (out of 3)\n",
      "\u001b[92mINFO \u001b[0m:      aggregate_evaluate: received 3 results and 0 failures\n",
      "\u001b[92mINFO \u001b[0m:      \n",
      "\u001b[92mINFO \u001b[0m:      [ROUND 5]\n",
      "\u001b[92mINFO \u001b[0m:      configure_fit: strategy sampled 3 clients (out of 3)\n",
      "\u001b[92mINFO \u001b[0m:      aggregate_fit: received 3 results and 0 failures\n",
      "\u001b[92mINFO \u001b[0m:      configure_evaluate: strategy sampled 3 clients (out of 3)\n",
      "\u001b[92mINFO \u001b[0m:      aggregate_evaluate: received 3 results and 0 failures\n",
      "\u001b[92mINFO \u001b[0m:      \n",
      "\u001b[92mINFO \u001b[0m:      [ROUND 6]\n",
      "\u001b[92mINFO \u001b[0m:      configure_fit: strategy sampled 3 clients (out of 3)\n",
      "\u001b[92mINFO \u001b[0m:      aggregate_fit: received 3 results and 0 failures\n",
      "\u001b[92mINFO \u001b[0m:      configure_evaluate: strategy sampled 3 clients (out of 3)\n",
      "\u001b[92mINFO \u001b[0m:      aggregate_evaluate: received 3 results and 0 failures\n",
      "\u001b[92mINFO \u001b[0m:      \n",
      "\u001b[92mINFO \u001b[0m:      [ROUND 7]\n",
      "\u001b[92mINFO \u001b[0m:      configure_fit: strategy sampled 3 clients (out of 3)\n",
      "\u001b[92mINFO \u001b[0m:      aggregate_fit: received 3 results and 0 failures\n",
      "\u001b[92mINFO \u001b[0m:      configure_evaluate: strategy sampled 3 clients (out of 3)\n",
      "\u001b[92mINFO \u001b[0m:      aggregate_evaluate: received 3 results and 0 failures\n",
      "\u001b[92mINFO \u001b[0m:      \n",
      "\u001b[92mINFO \u001b[0m:      [ROUND 8]\n",
      "\u001b[92mINFO \u001b[0m:      configure_fit: strategy sampled 3 clients (out of 3)\n",
      "\u001b[92mINFO \u001b[0m:      aggregate_fit: received 3 results and 0 failures\n",
      "\u001b[92mINFO \u001b[0m:      configure_evaluate: strategy sampled 3 clients (out of 3)\n",
      "\u001b[92mINFO \u001b[0m:      aggregate_evaluate: received 3 results and 0 failures\n",
      "\u001b[92mINFO \u001b[0m:      \n",
      "\u001b[92mINFO \u001b[0m:      [ROUND 9]\n",
      "\u001b[92mINFO \u001b[0m:      configure_fit: strategy sampled 3 clients (out of 3)\n",
      "\u001b[92mINFO \u001b[0m:      aggregate_fit: received 3 results and 0 failures\n",
      "\u001b[92mINFO \u001b[0m:      configure_evaluate: strategy sampled 3 clients (out of 3)\n",
      "\u001b[92mINFO \u001b[0m:      aggregate_evaluate: received 3 results and 0 failures\n",
      "\u001b[92mINFO \u001b[0m:      \n",
      "\u001b[92mINFO \u001b[0m:      [ROUND 10]\n",
      "\u001b[92mINFO \u001b[0m:      configure_fit: strategy sampled 3 clients (out of 3)\n",
      "\u001b[92mINFO \u001b[0m:      aggregate_fit: received 3 results and 0 failures\n",
      "\u001b[92mINFO \u001b[0m:      configure_evaluate: strategy sampled 3 clients (out of 3)\n",
      "\u001b[92mINFO \u001b[0m:      aggregate_evaluate: received 3 results and 0 failures\n",
      "\u001b[92mINFO \u001b[0m:      \n",
      "\u001b[92mINFO \u001b[0m:      [SUMMARY]\n",
      "\u001b[92mINFO \u001b[0m:      Run finished 10 round(s) in 31.46s\n",
      "\u001b[92mINFO \u001b[0m:      \tHistory (loss, distributed):\n",
      "\u001b[92mINFO \u001b[0m:      \t\tround 1: 0.08233207945497881\n",
      "\u001b[92mINFO \u001b[0m:      \t\tround 2: 0.06516618684211874\n",
      "\u001b[92mINFO \u001b[0m:      \t\tround 3: 0.052042546479598335\n",
      "\u001b[92mINFO \u001b[0m:      \t\tround 4: 0.045495548603697596\n",
      "\u001b[92mINFO \u001b[0m:      \t\tround 5: 0.0358797333995748\n",
      "\u001b[92mINFO \u001b[0m:      \t\tround 6: 0.03202725567432664\n",
      "\u001b[92mINFO \u001b[0m:      \t\tround 7: 0.027323391866980132\n",
      "\u001b[92mINFO \u001b[0m:      \t\tround 8: 0.021426389306228352\n",
      "\u001b[92mINFO \u001b[0m:      \t\tround 9: 0.016229799630479044\n",
      "\u001b[92mINFO \u001b[0m:      \t\tround 10: 0.017514978506550285\n",
      "\u001b[92mINFO \u001b[0m:      \n"
     ]
    }
   ],
   "source": [
    "# Iniciar a simulação\n",
    "run_simulation(\n",
    "    server_app=server,\n",
    "    client_app=client,\n",
    "    num_supernodes=NUM_PARTITIONS,\n",
    "    backend_config=backend_config,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "903926bc",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "flwr",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
